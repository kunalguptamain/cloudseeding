# -*- coding: utf-8 -*-
"""Copy of Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Hvaid7XH8FLrbF6__slaMil4y0ls_Ik
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install pyyaml h5py
# %pip install pennylane
import pennylane as qml
from pennylane import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import pandas as pd

import tensorflow as tf

from google.colab import drive
drive.mount('/content/drive')

# Read the CSV file
location = "/content/drive/MyDrive/test/inputs.csv"
df = pd.read_csv(location, index_col=0)

# Assuming df is your DataFrame and you want to normalize all integer columns
int_columns = df.select_dtypes(include=['int']).columns

scaler = MinMaxScaler()

df[int_columns] = scaler.fit_transform(df[int_columns])

df = df.drop(df.columns[0:1], axis=1)
df = df.drop(df.columns[-3:-1], axis=1)
indexs = [df.columns[i*5] for i in range(15) if not i in [2,3,10,13,6,7]]
df.drop(df.columns.difference(indexs), 1, inplace=True)

#df.drop(df.columns.difference(indexs), inplace=True, axis = 1)
df.info(verbose=True)
# Separate features (X) and target variable (y)
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

#df.info(verbose=True)

#print(y)

print(X_train)

n_qubits = 8  # Number of qubits
dev = qml.device("default.qubit", wires=n_qubits)  # Define quantum device

@qml.qnode(dev)
def quantum_node(inputs, weights):
    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))
    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))
    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]

n_layers = 6  # Number of layers in the quantum circuit
weight_shapes = {"weights": (n_layers, n_qubits)}

qlayer = qml.qnn.KerasLayer(quantum_node, weight_shapes, output_dim=n_qubits, name = "q")
clayer1 = tf.keras.layers.Dense(32, activation="relu")
clayer2 = tf.keras.layers.Dense(8, activation="relu")
clayer3 = tf.keras.layers.Dense(2, activation="softmax", name = "final")
model = tf.keras.models.Sequential([qlayer, clayer1, clayer2, clayer3])

opt = tf.keras.optimizers.Adam(learning_rate=0.01)
model.compile(opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=2)

model.save('/content/drive/MyDrive/test/')

history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, shuffle=True)

